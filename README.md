
<!--# Recent Stars 2020-->

<p align="center">
 <img width="100px" src="https://s4.aconvert.com/convert/p3r68-cdx67/ai8ay-7w5ao.svg" align="center" alt="Recent-Stars-2020" />
 <h1 align="center">Recent Stars 2020</h1>
 <p align="center">âœ” This repo collects some links with papers which I recently starred related on SLAM, Pose/Object tracking, Depth/Disparity/Flow Estimation, 3D-graphic, etc.</p>
</p>

<p align="center">
  <a href="https://github.com/Vincentqyw/Recent-Stars-2020">
    <img alt="Awesome" src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" />
  </a>
  <a href="http://hits.dwyl.io/Vincentqyw/Recent-Stars-2019">
    <img alt="HitCount" src="http://hits.dwyl.io/Vincentqyw/Recent-Stars-2019.svg" />
  </a>
  <a href="https://vincentqin.tech">
    <img alt="LICENSE" src="https://img.shields.io/badge/license-Anti%20996-blue.svg?style=flat-square" />
  </a>
</p>


<!--
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/Vincentqyw/Recent-Stars-2020)
[![HitCount](http://hits.dwyl.io/Vincentqyw/Recent-Stars-2019.svg)](http://hits.dwyl.io/Vincentqyw/Recent-Stars-2019)
[![LICENSE](https://img.shields.io/badge/license-Anti%20996-blue.svg?style=flat-square)](https://github.com/Vincentqyw/Recent-Stars-2020)
âœ” This repo collects some links with papers which I recently starred related on SLAM, Pose/Object tracking, Depth/Disparity/Flow Estimation, 3D-graphic, etc.
-->

## SLAM related

- [**SLAM**][ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM](https://github.com/UZ-SLAMLab/ORB_SLAM3), **[[PDF](https://arxiv.org/abs/2007.11898)]**

- [**SLAM**][LIO-SAM](https://github.com/TixiaoShan/LIO-SAM), æ¿€å…‰é›·è¾¾IMUç´§è€¦åˆSLAM

- [**Tool**][Robotics Toolbox for Python](https://github.com/petercorke/robotics-toolbox-python),  a Python implementation of the [Robotics Toolbox for MATLABÂ®](https://github.com/petercorke/robotics-toolbox-matlab)

- [**Matching**][LISRD](https://github.com/rpautrat/LISRD),ECCV 2020, **[[PDF](https://arxiv.org/abs/2007.08988)]**ï¼Œåœ¨çº¿å±€éƒ¨ä¸å˜ç‰¹å¾åŒ¹é…ï¼é‡è¦ï¼

- [**Matching**][AdaLAM](https://github.com/cavalli1234/AdaLAM),ç‰¹å¾åŒ¹é…å¿«é€Ÿæ»¤é™¤å¤–ç‚¹

- [**Calib**][fisheye_pinhole_calib_demo](https://github.com/3DCVer/fisheye_pinhole_calib_demo), åŒ…æ‹¬é±¼çœ¼æ¨¡å‹ã€é’ˆå­”æ¨¡å‹çš„ç›¸æœºæ ‡å®šï¼Œå°è£…äº†è‡ªåŠ¨ç¼–è¯‘ã€åº“çš„æ‰“åŒ…ä»¥åŠå¤–éƒ¨åº“çš„è°ƒç”¨æµ‹è¯•

- [**Calib**][SensorCalibration](https://github.com/FENGChenxi0823/SensorCalibration), IMUé›·è¾¾æ ‡å®š

- [**VO**][Low-Drift Visual Odometry in Structured Environments by Decoupling Rotational and Translational Motion](https://github.com/PyojinKim/LPVO),ICRA 2018, **[[PDF](http://pyojinkim.com/download/papers/2018_ICRA.pdf)]**, ç»“æ„åŒ–ç¯å¢ƒä¸­å°†æ—‹è½¬é‡ä¸å¹³ç§»é‡è¿›è¡Œåˆ†ç¦»ä¼˜åŒ–

- [**VIO**][VIO-SLAM](https://github.com/iamwangyabin/VIO-SLAM), ä»é›¶å¼€å§‹æ‰‹å†™VIOè¯¾åä½œä¸š

- [**Matching**][TFMatch: Learning-based image matching in TensorFlow](https://github.com/lzx551402/tfmatch),TensorFlow å®ç°çš„ GeoDesc,ASLFeatä»¥åŠContextDesc

- [**Tutorial**][SLAM-BOOK](https://github.com/yanyan-li/SLAM-BOOK), ä¸€æœ¬å…³äºSLAMçš„ä¹¦ç¨¿ï¼Œæ¸…æ¥šçš„ä»‹ç»SLAMç³»ç»Ÿä¸­çš„ä½¿ç”¨çš„å‡ ä½•æ–¹æ³•å’Œæ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ŒæŒç»­æ›´æ–°ä¸­

- [**Loop Closing**][OverlapNet - Loop Closing for 3D LiDAR-based SLAM](https://github.com/PRBonn/OverlapNet), RSS 2020, **[[PDF](https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2020rss.pdf)]**, 3Dæ¿€å…‰é›·è¾¾SLAMé—­ç¯

- [**SLAM**][VDO_SLAM](https://github.com/halajun/VDO_SLAM), RGB-Dç›¸æœºæ•°æ®ä½œä¸ºè¾“å…¥ï¼Œå®ç°è¿½è¸ªåŠ¨æ€ç‰©ä½“SLAMçš„åŠŸèƒ½, **[[PDF](https://arxiv.org/abs/2005.11052)]**

- [**SLAM**][orbslam-map-saving-extension](https://github.com/TUMFTM/orbslam-map-saving-extension)ï¼Œåœ¨ORB-SLAMçš„åŸºç¡€ä¸Šå¢åŠ ä¿å­˜+åŠ è½½åœ°å›¾åŠŸèƒ½

- [**Tutorial**][Modern Robotics: Mechanics, Planning, and Control Code Library](https://github.com/NxRLab/ModernRobotics), ç°ä»£æœºå™¨äººå­¦, **[[Homepage](http://hades.mech.northwestern.edu/index.php/Modern_Robotics)]**

- [**Matching**][image-matching-benchmark-baselines](https://github.com/vcg-uvic/image-matching-benchmark-baselines), å›¾åƒç‰¹å¾åŒ¹é…æŒ‘æˆ˜èµ›ä¸»é¡µ

- [**Matching**][GraphLineMatching](https://github.com/mameng1/GraphLineMatching)

- [**Matching**][Locality Preserving Matching](https://github.com/jiayi-ma/LPM), IJCAI 2017, **[[PDF](https://ai.tencent.com/ailab/media/publications/YuanGao_IJCAI2017_LocalityPreservingMatching.pdf)]**

- [**IMU**][IMUOrientationEstimator](https://github.com/ydsf16/IMUOrientationEstimator)

- [**Feature**][BEBLID: Boosted Efficient Binary Local Image Descriptor](https://github.com/iago-suarez/BEBLID)

- [**Relocalization**][KFNet: Learning Temporal Camera Relocalization using Kalman Filtering](https://github.com/zlthinker/KFNet),CVPR 2020,**[[PDF](https://arxiv.org/abs/2003.10629)]**

- [**Matching**][image-matching-benchmark](https://github.com/vcg-uvic/image-matching-benchmark)

- [**Matching**][GMS: Grid-based Motion Statistics for Fast, Ultra-robust Feature Correspondence](https://github.com/JiawangBian/GMS-Feature-Matcher),CVPR 17 & IJCV 19,**[[PDF](http://jwbian.net/Papers/GMS_CVPR17.pdf)]**,**[[Project page](http://jwbian.net/gms)]**

- [**Reloc**][GN-Net-Benchmark](https://github.com/Artisense-ai/GN-Net-Benchmark), CVPR 2020,GN-Net: The Gauss-Newton Loss for Multi-Weather Relocalization, **[[PDF](https://arxiv.org/abs/1904.11932)]**,**[[Project page](http://vision.in.tum.de/gn-net)]**

- [**Matching**][SuperGluePretrainedNetwork](https://github.com/magicleap/SuperGluePretrainedNetwork), CVPR 2020, **[[PDF](https://arxiv.org/abs/1911.11763)]**, åˆ’é‡ç‚¹ï¼2020å¹´sotaè¶…å¤§è§†è§’2Dç‰¹å¾åŒ¹é…ï¼Œ[Blog](https://www.vincentqin.tech/posts/superglue/)

- [**Feature**][D3Feat](https://github.com/XuyangBai/D3Feat), CVPR 2020, **[[PDF](https://arxiv.org/abs/2003.03164)]**

- [**Feature**][ASLFeat](https://github.com/lzx551402/ASLFeat), CVPR 2020, ASLFeat: Learning Local Features of Accurate Shape and Localization, **[[PDF](https://arxiv.org/abs/2003.10071)]**

- [**Feature**][GMS-Feature-Matcher](https://github.com/XuyangBai/D3Feat), CVPR 2018, GMS: Grid-based Motion Statistics for Fast, Ultra-robust Feature Correspondence, **[[PDF](http://jwbian.net/Papers/GMS_CVPR17.pdf)]**,**[[Project page](http://jwbian.net/gms)]**

- [**Feature**][D3Feat](https://github.com/XuyangBai/D3Feat), CVPR 2020, **[[PDF](https://arxiv.org/abs/2003.03164)]**

- [**Feature**][3DFeatNet](https://github.com/yewzijian/3DFeatNet), ECCV 2018, **[[PDF](https://arxiv.org/abs/1807.09413)]**

- [**Tutorial**][AutonomousDrivingCookbook](https://github.com/microsoft/AutonomousDrivingCookbook)ï¼ŒScenarios, tutorials and demos for Autonomous Driving

- [**Tutorial**][SLAMPaperReading](https://github.com/PaoPaoRobot/SLAMPaperReading)ï¼Œæ³¡æ³¡æœºå™¨äººåŒ—äº¬çº¿ä¸‹SLAMè®ºæ–‡åˆ†äº«èµ„æ–™

- [**Tutorial**][VIO_Tutotial_Course](https://github.com/lishuwei0424/VIO_Tutotial_Course)

- [**Tutorial**][VO-SLAM-Review](https://github.com/MichaelBeechan/VO-SLAM-Review)

- [**Tutorial**][VINS-Mono-code-annotation](https://github.com/QingSimon/VINS-Mono-code-annotation),VINS-Monoä»£ç æ³¨é‡Šä»¥åŠå…¬å¼æ¨å¯¼

- [**Tutorial**][VINS-Mono-Learning](https://github.com/ManiiXu/VINS-Mono-Learning),VINS-Monoä»£ç æ³¨é‡Š

- [**Tutorial**][VINS-Course](https://github.com/HeYijia/VINS-Course),VINS-Mono code without Ceres or ROS

- [**Tutorial**][VIO-Doc](https://github.com/StevenCui/VIO-Doc),ä¸»æµVIOè®ºæ–‡æ¨å¯¼åŠä»£ç è§£æ

- [**VO**][CNN-DSO](https://github.com/muskie82/CNN-DSO), Direct Sparse Odometry with CNN Depth Prediction

- [**VO**][fisheye-ORB-SLAM](https://github.com/lsyads/fisheye-ORB-SLAM), A real-time robust monocular visual SLAM system based on ORB-SLAM for fisheye cameras, without rectifying or cropping the input images

- [**VO**][ORB_Line_SLAM](https://github.com/robotseu/ORB_Line_SLAM), Real-Time SLAM with BoPLW Pairs for Stereo Cameras, with Loop Detection and Relocalization Capabilities

- [**VO**][DeepVO-pytorch](https://github.com/ChiWeiHsiao/DeepVO-pytorch.git), ICRA 2017 [DeepVO: Towards end-to-end visual odometry with deep Recurrent Convolutional Neural Networks](https://ieeexplore.ieee.org/document/7989236/)

- [**Calib**][CamOdomCalibraTool](https://github.com/MegviiRobot/CamOdomCalibraTool), The tool to calibrate extrinsic param between camera and wheel.

- [**Calib**][lidar_camera_calibration](https://github.com/heethesh/lidar_camera_calibration),[another version](https://github.com/ankitdhall/lidar_camera_calibration)

- [**Calib**][OdomLaserCalibraTool](https://github.com/MegviiRobot/OdomLaserCalibraTool.git)ï¼Œç›¸æœºä¸2Dé›·è¾¾æ ‡å®š

- [**Calib**][extrinsic_lidar_camera_calibration](https://github.com/UMich-BipedLab/extrinsic_lidar_camera_calibration), LiDARTag: A Real-Time Fiducial Tag using Point Clouds, arXiv 2019, **[[PDF](https://arxiv.org/abs/1908.10349)]**

- [**Calib**][velo2cam_calibration](https://github.com/beltransen/velo2cam_calibration), Automatic Calibration algorithm for Lidar-Stereo camera, **[[Project page](http://wiki.ros.org/velo2cam_calibration)]**

- [**Dataset**][IRS: A Large Synthetic Indoor Robotics Stereo Dataset for Disparity and Surface Normal Estimation](https://github.com/HKBU-HPML/IRS.git)

- [**Tools**][averaging-quaternions](https://github.com/christophhagen/averaging-quaternions),å››å…ƒæ•°å¹³å‡

---
åˆ†å‰²çº¿ï¼Œä»¥ä¸‹æ˜¯2019å¹´çš„æ˜Ÿæ ‡é¡¹ç›®ï¼Œä¸Šé¢æ˜¯2020å¹´æ–°æ˜Ÿæ ‡çš„ã€‚

- [R2D2: Reliable and Repeatable Detector and Descriptor](https://github.com/naver/r2d2),NeurIPS 2019,**[[PDF](https://arxiv.org/abs/1906.06195)]**,**[[Project page](https://europe.naverlabs.com/research/publications/r2d2-reliable-and-repeatable-detectors-and-descriptors-for-joint-sparse-local-keypoint-detection-and-feature-extraction/)]**ï¼Œæ·±åº¦å­¦ä¹ ç‰¹å¾ç‚¹+æè¿°å­

- [Semantic_SLAM](https://github.com/1989Ryan/Semantic_SLAM),è¯­ä¹‰SLAMï¼šROS + ORB SLAM + PSPNet101

- [PlaceRecognition-LoopDetection](https://github.com/BAILOOL/PlaceRecognition-LoopDetection), Light-weight place recognition and loop detection using road markings

- [DOOR-SLAM: Distributed, online, and outlier resilient SLAM for robotic teams](https://github.com/MISTLab/DOOR-SLAM),**[[PDF](https://arxiv.org/abs/1909.12198)]**,**[[Project page](https://mistlab.ca/DOOR-SLAM/)]**ï¼Œå¤šæœºå™¨äººåä½œSLAMï¼Œå¢å¼ºäº†åœºæ™¯çš„é€‚ç”¨æ€§

- [awesome-local-global-descriptor](https://github.com/shamangary/awesome-local-global-descriptor), è¶…è¯¦ç»†æ·±åº¦å­¦ä¹ ç‰¹å¾ç‚¹æè¿°å­é›†åˆï¼Œéœ€è¦é‡ç‚¹å…³æ³¨ä¸€ä¸‹è¿™ä¸ªrepo

- [GIFT: Learning Transformation-Invariant Dense Visual Descriptors via Group CNNs](https://github.com/zju3dv/GIFT), NeurIPS 2019ï¼Œ**[[PDF](https://arxiv.org/abs/1911.05932)]**, **[[Project page](https://zju3dv.github.io/GIFT/)]**ï¼Œæµ™å¤§CAD+å•†æ±¤è”åˆå®éªŒå®¤å‡ºå“ï¼Œåˆ©ç”¨Group CNNæ¥æ”¹è¿›superpointæè¿°å­ï¼ˆä»…æè¿°ï¼Œç‰¹å¾ç‚¹æå–å¯ä»»æ„é€‰æ‹©ï¼‰ï¼Œå¯ä»¥å¤§å¹…åº¦å¢å¼ºè§†è§’å˜åŒ–æ—¶çš„ç‰¹å¾ç‚¹å¤æ£€ç‡ä¸åŒ¹é…ç‚¹æ•°

- [Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters](https://github.com/axelBarroso/Key.Net),ICCV 2019, **[[PDF](https://arxiv.org/abs/1904.00889)]**, æ·±åº¦å­¦ä¹ ç‰¹å¾ç‚¹

- [Self-Supervised 3D Keypoint Learning for Ego-motion Estimation](https://github.com/TRI-ML/KP3D),**[[PDF](https://arxiv.org/abs/1912.03426)]**,**[[Youtube](https://www.youtube.com/watch?v=4hFhSD8QUPM)]**, æ·±åº¦å­¦ä¹ ç‰¹å¾ç‚¹

- [VINS-Mono-Optimization](https://github.com/Jichao-Peng/VINS-Mono-Optimization), å®ç°ç‚¹çº¿ç´§è€¦åˆä¼˜åŒ–çš„VINS-Mono

- [msckf_vioæ³¨é‡Šç‰ˆæœ¬](https://github.com/PetWorm/msckf_vio_zhushi)

- [NetVLAD-pytorch](https://github.com/lyakaap/NetVLAD-pytorch), NetVLADåœºæ™¯è¯†åˆ«çš„pytorchå®ç°

- [High-Precision Localization Using Ground Texture (Micro-GPS)](http://microgps.cs.princeton.edu/),ECCV 2018,**[[PDF](https://arxiv.org/abs/1710.10687)]**,**[[Project page](http://microgps.cs.princeton.edu/)]**,**[[code](http://microgps.cs.princeton.edu/data/micro-gps-cpp-master.zip)]**ï¼Œåœ°å‘ï¼ˆæ‘„åƒæœºæœå‘åœ°é¢ï¼‰SLAMï¼Œè·å¾—é«˜ç²¾åº¦é‡å®šä½æ•ˆæœã€‚

- [PlaneSLAM](https://github.com/LRMPUT/PlaneSLAM), Paper: â€œOn the Representation of Planes for Efficient Graph-based SLAM with High-level Featuresâ€

- [XIVO: X Inertial-aided Visual Odometry and Sparse Mapping](https://github.com/ucla-vision/xivo), an open-source repository for visual-inertial odometry/mapping. 

- [DeepTAM](https://github.com/lmb-freiburg/deeptam),ECCV 2018,**[[PDF](https://arxiv.org/pdf/1808.01900.pdf)]**,**[[Project page](https://lmb.informatik.uni-freiburg.de/people/zhouh/deeptam/)]**,a learnt system for keyframe-based dense camera tracking and mapping.

- [iRotAvg, Why bundle adjust?](https://github.com/ajparra/iRotAvg),ICRA 2019,**[[PDF](https://cs.adelaide.edu.au/~aparra/publication/parra19_icra/)]**
- [Tactical Rewind: Self-Correction via Backtracking in Vision-and-Language Navigation](https://github.com/Kelym/FAST),CVPR 2019,**[[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Ke_Tactical_Rewind_Self-Correction_via_Backtracking_in_Vision-And-Language_Navigation_CVPR_2019_paper.html)]**ï¼Œè§†è§‰+è¯­è¨€å¯¼èˆª
- [DOOR-SLAM](https://github.com/MISTLab/DOOR-SLAM)
- [An Evaluation of Feature Matchers for Fundamental Matrix Estimation](https://github.com/JiawangBian/FM-Bench),BMVC 2019,**[[PDF](https://jwbian.net/Papers/FM_BMVC19.pdf)]**,**[[Project Page](http://jwbian.net/fm-bench)]**ï¼Œç‰¹å¾åŒ¹é…
- [A Tightly Coupled 3D Lidar and Inertial Odometry and Mapping Approach](https://github.com/hyye/lio-mapping),ICRA 2019,**[[PDF](https://arxiv.org/abs/1904.06993)]**,**[[Project Page](https://sites.google.com/view/lio-mapping)]**ï¼Œç´§è€¦åˆé›·è¾¾+IMU SLAM
- [On the Representation of Planes for Efficient Graph-based SLAM with High-level Features](https://github.com/LRMPUT/PlaneSLAM),åˆ©ç”¨å¹³é¢ä¿¡æ¯çš„SLAM
- [Visual Odometry Revisited: What Should Be Learnt?](https://github.com/Huangying-Zhan/DF-VO),arXiv 2019,**[[PDF](https://arxiv.org/abs/1909.09803)]**, æ·±åº¦å­¦ä¹ æ·±åº¦+å…‰æµè¿›è¡ŒVO
- [RF-Net: An End-to-End Image Matching Network based on Receptive Field](https://github.com/Xylon-Sean/rfnet),CVPR 2019,**[[PDF](https://arxiv.org/abs/1906.00604)]**, ç«¯åˆ°ç«¯å›¾åƒåŒ¹é…
- [Fast-Planner](https://github.com/HKUST-Aerial-Robotics/Fast-Planner),IEEE Robotics and Automation Letters (RA-L), 2019,**[[PDF](https://ieeexplore.ieee.org/document/8758904)]**, æ— äººæœºè½¨è¿¹ç”Ÿæˆ
- [A general and flexible factor graph non-linear least square optimization framework](https://github.com/dongjing3309/minisam),CoRR 2019,**[[PDF](http://arxiv.org/abs/1909.00903)]**,**[[Project Page](https://minisam.readthedocs.io/)]**
- [Demo for Kalman filter in ranging system](https://github.com/gao-ouyang/demo_for_kalmanFilter),å¡å°”æ›¼æ»¤æ³¢åŸç†æ¼”ç¤º
- [A Holistic Visual Place Recognition Approach using Lightweight CNNs for Severe ViewPoint and Appearance Changes](https://github.com/Ahmedest61/CNN-Region-VLAD-VPR)ï¼Œåœºæ™¯è¯†åˆ«ï¼ˆå¤–è§‚ä¸è§†è§’å˜åŒ–æ—¶ï¼‰,[è®­ç»ƒå’Œéƒ¨ç½²æºç ](https://github.com/ethz-asl/hierarchical_loc)
- [SIPs: Succinct Interest Points from Unsupervised Inlierness Probability Learning](https://github.com/uzh-rpg/sips2_open),3D Vision (3DV) 2019,**[[PDF](https://arxiv.org/abs/1805.01358)]**ï¼ŒRPGå®éªŒå®¤å‡ºå“ï¼Œæ·±åº¦å­¦ä¹ ç‰¹å¾ç‚¹ï¼ˆæœ‰ç‰¹å¾æè¿°å­ï¼‰

- [Matching Features Without Descriptors: Implicitly Matched Interest Points](https://github.com/uzh-rpg/imips_open),BMVC 2019,**[[PDF](http://rpg.ifi.uzh.ch/docs/BMVC19_Cieslewski.pdf)]**,RPGå®éªŒå®¤å‡ºå“ï¼Œæ— éœ€ç‰¹å¾æè¿°å³å¯è¿›è¡Œç‰¹å¾åŒ¹é…

- [Learning Lightweight Lane Detection CNNs by Self Attention Distillation (ICCV 2019)](https://github.com/cardwing/Codes-for-Lane-Detection),ICCV 2019,**[[PDF](https://arxiv.org/abs/1908.00821)]**ï¼Œæ·±åº¦å­¦ä¹ é“è·¯æ£€æµ‹

- [Awesome SLAM Datasets](https://github.com/youngguncho/awesome-slam-datasets),å²ä¸Šæœ€å…¨SLAMæ•°æ®é›†ï¼Œ **[å…¬ä¼—å·è¯´æ˜: æœ€å…¨ SLAM å¼€æºæ•°æ®é›†](https://mp.weixin.qq.com/s/BzcghUnXTR9RQqA3Pc9MhA)**

- [GNSS-INS-SIM](https://github.com/Aceinna/gnss-ins-sim),æƒ¯å¯¼èåˆæ¨¡æ‹Ÿå™¨ï¼Œæ”¯æŒIMUæ•°æ®ï¼Œè½¨è¿¹ç”Ÿæˆç­‰

- [Multi-Sensor Combined Navigation Program(GNSS, IMU, Camera and so on) å¤šæºå¤šä¼ æ„Ÿå™¨èåˆå®šä½ GPS/INSç»„åˆå¯¼èˆª](https://github.com/2013fangwentao/Multi-Sensor-Combined-Navigation)

- [SOSNet: Second Order Similarity Regularization for Local Descriptor Learning](https://github.com/scape-research/SOSNet),CVPR 2019,**[[Project page]](https://research.scape.io/sosnet/)** **[[Paper]](https://arxiv.org/abs/1904.05019)** **[[Poster]](imgs/sosnet-poster.pdf)** **[[Slides]](imgs/sosnet-oral.pdf)**ï¼Œä¸€ç§æ·±åº¦å­¦ä¹ ç‰¹å¾æè¿°å­

- [Look No Deeper: Recognizing Places from Opposing Viewpoints under Varying Scene Appearance using Single-View Depth Estimation](https://github.com/oravus/seq2single),ICRA 2019,**[[PDF](https://arxiv.org/abs/1902.07381)]**,åˆ©ç”¨æ·±åº¦å›¾åƒå®ç°äº†å¤§è§†è§’é•¿æ—¶é—´çš„åœºæ™¯è¯†åˆ«ï¼ˆæ ¹æ®æ·±åº¦å›¾ç­›é€‰å¾—åˆ°ä¸åŒæ·±åº¦å±‚æ¬¡çš„ç‰¹å¾ç‚¹ç„¶åä¸å½“å‰å¸§è¿›è¡ŒåŒ¹é…ï¼Œæé«˜äº†åœºæ™¯å¬å›ç‡ï¼‰

- [CALC2.0](https://github.com/rpng/calc2.0),Convolutional Autoencoder for Loop Closure 2.0,ç”¨äºé—­ç¯æ£€æµ‹

- [SegMap](https://github.com/ethz-asl/segmap),RSS 2018,**[[PDF](http://www.roboticsproceedings.org/rss14/p03.pdf)]**, ä¸€ç§åŸºäº3Dçº¿æ®µçš„åœ°å›¾è¡¨ç¤ºï¼Œå¯ç”¨äºåœºæ™¯è¯†åˆ«/æœºå™¨äººå®šä½/ç¯å¢ƒé‡å»ºç­‰

- [MSCKF_VIO](https://github.com/cggos/msckf_vio_cg), a stereo version of MSCKFï¼ŒåŸºäºMSCKFçš„åŒç›®VIO

- [NetVLAD: CNN architecture for weakly supervised place recognition](https://github.com/Relja/netvlad)ï¼ŒCVPR 2016, CNNæ¡†æ¶å¼±ç›‘ç£å­¦ä¹ åœºæ™¯è¯†åˆ«,**[[Project Page](https://www.di.ens.fr/willow/research/netvlad/)]**

- [easy_handeye](https://github.com/IFL-CAMP/easy_handeye),Simple, straighforward ROS library for hand-eye calibration

- [SuperPoint-SLAM](https://github.com/KinglittleQ/SuperPoint_SLAM),åˆ©ç”¨SuperPointæ›¿æ¢ORBç‰¹å¾ç‚¹

- [PyRobot: An Open Source Robotics Research Platform](https://github.com/facebookresearch/pyrobot)

- [From Coarse to Fine: Robust Hierarchical Localization at Large Scale with HF-Net](https://github.com/ethz-asl/hfnet),**[[PDF](https://arxiv.org/abs/1812.03506)]**

- [Super fast implementation of ICP in CUDA](https://github.com/mp3guy/ICPCUDA)

- [ A generic interface for disparity map and pointcloud insertion](https://github.com/ethz-asl/volumetric_mapping)

- [SPHORB: A Fast and Robust Binary Feature on the Sphere](https://github.com/tdsuper/SPHORB),International Journal of Computer Vision 2015,**[[PDF](http://scs.tju.edu.cn/~lwan/paper/SPHORB/pdf/SPHORB-final-small.pdf)]**,**[[Project Page](http://scs.tju.edu.cn/~lwan/paper/SPHORB/SPHORB.html)]**

- [BADSLAM: Bundle Adjusted Direct RGB-D SLAM](https://github.com/ETH3D/badslam),CVPR 2019,**[[PDF](http://openaccess.thecvf.com/content_CVPR_2019/papers/Schops_BAD_SLAM_Bundle_Adjusted_Direct_RGB-D_SLAM_CVPR_2019_paper.pdf)]**

- [High Speed and High Dynamic Range Video with an Event Camera](https://github.com/uzh-rpg/rpg_e2vid),arXiv,**[[PDF](http://rpg.ifi.uzh.ch/docs/arXiv19_Rebecq.pdf)]**,**[[Project Page](http://rpg.ifi.uzh.ch/E2VID.html)]**

- [Awesome-VIO](https://github.com/PaoPaoRobot/Awesome-VIO),Discuss about VIO in PaoPaoRobot group
- [GyroAllan](https://github.com/XinLiGH/GyroAllan),é™€èºä»ªéšæœºè¯¯å·®çš„ Allan æ–¹å·®åˆ†æ, [Another version](https://github.com/rpng/kalibr_allan)

- [Self-supervised Sparse-to-Dense: Self-supervised Depth Completion from LiDAR and Monocular Camera](https://github.com/fangchangma/self-supervised-depth-completion),ICRA 2019,**[[PDF](https://arxiv.org/pdf/1807.00275.pdf)]**, ä¼˜åŒ–LiDARä»¥åŠå•ç›®å¾—åˆ°çš„æ·±åº¦å›¾
- [PlaneRCNN: 3D Plane Detection and Reconstruction from a Single Image](https://github.com/NVlabs/planercnn),CVPR 2019,**[[PDF](https://arxiv.org/pdf/1812.04072.pdf)]**,**[[Project Page](https://research.nvidia.com/publication/2019-06_PlaneRCNN)]**,é€šè¿‡å•å¹…å›¾åƒè¿›è¡Œ3Då¹³é¢æ£€æµ‹ä»¥åŠé‡å»º
- [DBow3](https://github.com/kokerf/DBow3),æ³¨é‡Šç‰ˆçš„DBow3ä»£ç 
- [Visual-Inertial Mapping with Non-Linear Factor Recovery](https://github.com/VladyslavUsenko/basalt-mirror),**[[PDF](https://arxiv.org/abs/1904.06504)]**,**[[Project Page](https://vision.in.tum.de/research/vslam/basalt)]**, æ—¶ç©ºè”åˆçš„VIOä¼˜åŒ–æ–¹æ¡ˆ
- [ICRA2019-paper-list](https://github.com/PaoPaoRobot/ICRA2019-paper-list),ICRA 2019è®ºæ–‡åˆ—è¡¨ï¼ˆæ³¡æ³¡æœºå™¨äººå‡ºå“æš‚æ—¶æ— é“¾æ¥ï¼‰
- [Fast Cylinder and Plane Extraction from Depth Cameras for Visual Odometry](https://github.com/pedropro/CAPE), IROS 2018,**[[PDF](https://arxiv.org/abs/1803.02380)]**,åˆ©ç”¨æ·±åº¦å›¾è¿›è¡Œåœ†æŸ±æ£€æµ‹ä»¥åŠå¹³é¢æ£€æµ‹è¿›è¡ŒVO
- [Solutions to assignments of Robot Mapping Course WS 2013/14 by Dr. Cyrill Stachniss at University of Freiburg](https://github.com/kiran-mohan/SLAM-Algorithms-Octave),SLAMç®—æ³•å­¦ä¹ è¯¾åä½œä¸šç­”æ¡ˆ
- [Direct sparse odometry combined with stereo cameras and IMU](https://github.com/RonaldSun/VI-Stereo-DSO),åŒç›®DSO+IMU
- [Direct Sparse Odometry with Stereo Cameras](https://github.com/HorizonAD/stereo_dso),åŒç›®DSO
- [Python binding of SLAM graph optimization framework g2o](https://github.com/uoip/g2opy),pythonç‰ˆæœ¬çš„g2oå®ç°
- [SuperPoint: Self-Supervised Interest Point Detection and Description](https://github.com/rpautrat/SuperPoint), CVPR 2018, **[[Paper](https://arxiv.org/abs/1712.07629)]**, æ·±åº¦å­¦ä¹ æè¿°å­+æè¿°
- [ContextDesc: Local Descriptor Augmentation with Cross-Modality Context](https://github.com/lzx551402/contextdesc), CVPR 2019, **[[Paper](https://arxiv.org/abs/1904.04084)]**, æ·±åº¦å­¦ä¹ æè¿°å­
- [D2-Net: A Trainable CNN for Joint Description and Detection of Local Features](https://github.com/mihaidusmanu/d2-net), CVPR 2019, **[[Paper](https://arxiv.org/abs/1905.03561)]**, **[[Project Page](https://dsmn.ml/publications/d2-net.html)]**, æ·±åº¦å­¦ä¹ å…³é”®ç‚¹+æè¿°
- [ROS interface for ORBSLAM2](https://github.com/ethz-asl/orb_slam_2_ros),ROSç‰ˆæœ¬çš„ORBSLAM2
- [CNN-SVO: Improving the Mapping in Semi-Direct Visual Odometry Using Single-Image Depth Prediction](https://github.com/yan99033/CNN-SVO)ï¼Œ **[[Paper](https://arxiv.org/pdf/1810.01011.pdf)]**
- [VINS-Mono-Learning](https://github.com/ManiiXu/VINS-Mono-Learning)ï¼Œä»£ç æ³¨é‡Šç‰ˆVINS-Monoï¼Œåˆå­¦è€…å­¦ä¹ 
- [OpenVSLAM: Versatile Visual SLAM Framework](https://github.com/xdspacelab/openvslam), **[[Project Page](https://openvslam.readthedocs.io/)]**
- [RESLAM: A real-time robust edge-based SLAM system](https://github.com/fabianschenk/RESLAM), ICRA 2019, **[[Paper](https://github.com/fabianschenk/fabianschenk.github.io/raw/master/files/schenk_icra_2019.pdf)]**
- [PL-SLAM: a Stereo SLAM System through the Combination of Points and Line Segments](https://github.com/rubengooj/pl-slam), **[[Paper](https://arxiv.org/abs/1705.09479)]**ï¼Œçº¿ç‰¹å¾SLAM
- [Good Line Cutting: towards Accurate Pose Tracking of Line-assisted VO/VSLAM](https://github.com/YipuZhao/GF_PL_SLAM), ECCV 2018, **[[Project Page](https://sites.google.com/site/zhaoyipu/good-feature-visual-slam)]**, æ”¹è¿›çš„PL-SLAM
- [Spherical Regression: Learning Viewpoints, Surface Normals and 3D Rotations on n-Spheres](https://github.com/leoshine/Spherical_Regression), CVPR 2019, **[[Paper](http://arxiv.org/abs/1904.05404)]**
- [svo_edgelet](https://github.com/icsl-Jeon/traj_gen_vis), åœ¨çº¿è½¨è¿¹ç”Ÿæˆ
- [Drone SLAM project for Caltech's ME 134 Autonomy class](https://github.com/TimboKZ/caltech_samaritan), **[[PDF](https://github.com/TimboKZ/caltech_samaritan/blob/master/CS134_Final_Project_Report.pdf)]**
- [Online Trajectory Generation of a MAV for Chasing a Moving Target in 3D Dense Environments](https://github.com/icsl-Jeon/traj_gen_vis), **[[Paper](https://arxiv.org/pdf/1904.03421.pdf)]**
- [PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics),**[[Paper](https://arxiv.org/abs/1808.10703)]**, [CppRobotics](https://github.com/onlytailei/CppRobotics)
- [Bundle adjustment demo using Ceres Solver](https://github.com/izhengfan/ba_demo_ceres),  **[[Blog](https://fzheng.me/2018/01/23/ba-demo-ceres/)]**, cereså®ç°BA
- [CubeSLAM: Monocular 3D Object Detection and SLAM](https://github.com/shichaoy/cube_slam), **[[Paper](https://arxiv.org/abs/1806.00557)]**
- [PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud](https://github.com/sshaoshuai/PointRCNN), CVPR 2019, **[[Paper](https://arxiv.org/abs/1812.04244)]**
- [GIST-Global Image Descriptor](https://github.com/nrupatunga/GIST-global-Image-Descripor), GISTæè¿°å­
- [mav voxblox planning](https://github.com/ethz-asl/mav_voxblox_planning), MAV planning tools using voxblox as the map representation.
- [Python Kalman Filter](https://github.com/zziz/kalman-filter), 30è¡Œå®ç°å¡å°”æ›¼æ»¤æ³¢
- [vicalib](https://github.com/arpg/vicalib), è§†è§‰æƒ¯å¯¼ç³»ç»Ÿæ ‡å®šå·¥å…·
- [BreezySLAM](https://github.com/simondlevy/BreezySLAM), åŸºäºé›·è¾¾çš„SLAMï¼Œæ”¯æŒPython(&Matlab, C++, and Java)
- [Probabilistic-Robotics](https://github.com/Yvon-Shong/Probabilistic-Robotics), ã€Šæ¦‚ç‡æœºå™¨äººã€‹ä¸­æ–‡ç‰ˆï¼Œä¹¦å’Œè¯¾åä¹ é¢˜
- [Stanford Self Driving Car Code](https://github.com/emmjaykay/stanford_self_driving_car_code), **[[Paper](http://robots.stanford.edu/papers/junior08.pdf)]**, æ–¯å¦ç¦è‡ªåŠ¨é©¾é©¶è½¦ä»£ç 
- [Udacity Self-Driving Car Engineer Nanodegree projects](https://github.com/ndrplz/self-driving-car)
- [Artificial Intelligence in Automotive Technology](https://github.com/TUMFTM/Lecture_AI_in_Automotive_Technology), TUMè‡ªåŠ¨é©¾é©¶æŠ€æœ¯ä¸­çš„äººå·¥æ™ºèƒ½è¯¾ç¨‹
- [DeepMatchVO: Beyond Photometric Loss for Self-Supervised Ego-Motion Estimation](https://github.com/hlzz/DeepMatchVO),ICRA 2019, **[[Paper](https://arxiv.org/abs/1902.09103)]**
- [GSLAM: A General SLAM Framework and Benchmark](https://github.com/zdzhaoyong/GSLAM), CVPR 2019, **[[Paper](https://arxiv.org/abs/1902.07995)]**, é›†æˆäº†å„ç§ä¼ æ„Ÿå™¨è¾“å…¥çš„SLAMç»Ÿä¸€æ¡†æ¶
- [Visual-Odometric Localization and Mapping for Ground Vehicles Using SE(2)-XYZ Constraints](https://github.com/izhengfan/se2lam)ï¼ŒICRA 2019,åŸºäºSE(2)-XYZçº¦æŸçš„VOç³»ç»Ÿ
- [Simple bag-of-words loop closure for visual SLAM](https://github.com/nicolov/simple_slam_loop_closure), **[[Blog](https://nicolovaligi.com/bag-of-words-loop-closure-visual-slam.html)]**, å›ç¯
- [FBOW (Fast Bag of Words), an extremmely optimized version of the DBow2/DBow3 libraries](https://github.com/rmsalinas/fbow),ä¼˜åŒ–ç‰ˆæœ¬çš„DBow2/DBow3
- [Multi-State Constraint Kalman Filter (MSCKF) for Vision-aided Inertial Navigation(master's thesis)](https://github.com/tomas789/tonav)
- [MSCKF](https://github.com/yuzhou42/MSCKF), MSCKFä¸­æ–‡æ³¨é‡Šç‰ˆ
- [Calibration algorithm for a camera odometry system](https://github.com/hbtang/calibcamodo), VOç³»ç»Ÿçš„æ ‡å®šç¨‹åº
- [Modified version of VINS-Mono](https://github.com/cggos/vins_mono_cg), æ³¨é‡Šç‰ˆæœ¬VINS Mono
- [Extreme Relative Pose Estimation for RGB-D Scans via Scene Completion](https://github.com/zhenpeiyang/RelativePose),**[[Paper](https://arxiv.org/abs/1901.00063)]**
- [Implementation of EPnP algorithm with Eigen](https://github.com/jessecw/EPnP_Eigen),åˆ©ç”¨Eigenç¼–å†™çš„EPnP
- [Real-time SLAM system with deep features](https://github.com/jiexiong2016/GCNv2_SLAM), æ·±åº¦å­¦ä¹ æè¿°å­(ORB vs. GCNv2)
- [Unsupervised Learning of Monocular Depth Estimation and Visual Odometry with Deep Feature Reconstruction](https://github.com/Huangying-Zhan/Depth-VO-Feat), CVPR 2018, æ— ç›‘ç£å•ç›®æ·±åº¦æ¢å¤ä»¥åŠVO
- [ORB-SLAM-windows](https://github.com/Phylliida/orbslam-windows), Windowsç‰ˆæœ¬çš„ORB-SLAM
- [StructVIO : Visual-inertial Odometry with Structural Regularity of Man-made Environments](https://github.com/danping/structvio),**[[Project Page](http://drone.sjtu.edu.cn/dpzou/project/structvio.html)]**
- [KalmanFiltering](https://github.com/irvingzhang/KalmanFiltering), å„ç§å¡å°”æ›¼æ»¤æ³¢å™¨çš„demo
- [Stereo Odometry based on careful Feature selection and Tracking](https://github.com/ZhenghaoFei/visual_odom), **[[Paper](https://lamor.fer.hr/images/50020776/Cvisic2017.pdf)]**, C++ OpenCVå®ç°SOFT
- [Visual SLAM with RGB-D Cameras based on Pose Graph Optimization](https://github.com/dzunigan/zSLAM)
- [Multi-threaded generic RANSAC implemetation](https://github.com/drsrinathsridhar/GRANSAC), å¤šçº¿ç¨‹RANSAC
- [Visual Odometry with Drift-Free Rotation Estimation Using Indoor Scene Regularities](https://github.com/PyojinKim/OPVO), BMVC 2017, **[[Project Page](http://pyojinkim.me/pub/Visual-Odometry-with-Drift-Free-Rotation-Estimation-Using-Indoor-Scene-Regularities/)]**ï¼Œåˆ©ç”¨å¹³é¢æ­£äº¤ä¿¡æ¯è¿›è¡ŒVO
- [ICE-BA](https://github.com/baidu/ICE-BA), CVPR 2018, **[[Paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_ICE-BA_Incremental_Consistent_CVPR_2018_paper.pdf)]**
- [GraphSfM: Robust and Efficient Graph-based Structure from Motion](https://github.com/AIBluefisher/GraphSfM), **[[Project Page](https://aibluefisher.github.io/GraphSfM/)]**
- [LOAM_NOTED](https://github.com/cuitaixiang/LOAM_NOTED), loamä¸­æ–‡æ³¨è§£ç‰ˆ
- [Divide and Conquer: Effcient Density-Based Tracking of 3D Sensors in Manhattan Worlds](https://github.com/Ethan-Zhou/MWO),ACCV 2016,**[[Project Page](http://users.cecs.anu.edu.au/~u5535909/)]**,æ›¼å“ˆé¡¿ä¸–ç•Œåˆ©ç”¨æ·±åº¦ä¼ æ„Ÿå™¨è¿›è¡Œæ—‹è½¬é‡å¹³ç§»é‡åˆ†ç¦»ä¼˜åŒ–
- [Real-time Manhattan World Rotation Estimation in 3D](https://github.com/jstraub/rtmf),IROS 2015,å®æ—¶æ›¼å“ˆé¡¿ä¸–ç•Œæ—‹è½¬ä¼°è®¡

- [Event-based Vision Resources](https://github.com/uzh-rpg/event-based_vision_resources)ï¼Œå…³äºäº‹ä»¶ç›¸æœºçš„èµ„æº
- [AutonomousVehiclePaper](https://github.com/DeepTecher/AutonomousVehiclePaper)ï¼Œæ— äººé©¾é©¶ç›¸å…³è®ºæ–‡é€Ÿé€’
- [Segmentation.X](https://github.com/wutianyiRosun/Segmentation.X), Segmentationç›¸å…³è®ºæ–‡&ä»£ç 
- [CVPR-2019](https://github.com/amusi/CVPR2019-Code), CVPR 2019 è®ºæ–‡å¼€æºé¡¹ç›®åˆé›†
- [awesome-slam](https://github.com/kanster/awesome-slam), SLAMåˆé›†
- [awesome-visual-slam](https://github.com/tzutalin/awesome-visual-slam), è§†è§‰SLAMåˆé›†
- [Papers with code](https://github.com/zziz/pwc), å‘¨æ›´è®ºæ–‡withä»£ç 
- [Awesome Human Pose Estimation](https://github.com/cbsudux/awesome-human-pose-estimation),[awesome-object-pose](https://github.com/nkalavak/awesome-object-pose), ä½å§¿ä¼°è®¡åˆé›†
- [MVision](https://github.com/Ewenwan/MVision), å¤§ç¤¼åŒ…ï¼šæœºå™¨äººè§†è§‰ ç§»åŠ¨æœºå™¨äºº VS-SLAM ORB-SLAM2 æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹ yolov3 è¡Œä¸ºæ£€æµ‹ opencv PCL æœºå™¨å­¦ä¹  æ— äººé©¾é©¶

## Pose/Object tracking

- [Unsupervised person re-identification by soft multilabel learning](https://github.com/KovenYu/MAR),CVPR 2019,  **[[Paper](https://kovenyu.com/papers/2019_CVPR_MAR.pdf)]**

- [FCOS: Fully Convolutional One-Stage Object Detection](https://github.com/tianzhi0549/FCOS),ICCV 2019,  **[[Paper](https://arxiv.org/abs/1904.01355)]**

- [Hand Detection and Orientation Estimation](https://github.com/yangli18/hand_detection)
- [Spatial-Temporal Person Re-identification](https://github.com/Wanggcong/Spatial-Temporal-Re-identification),AAAI 2019,**[[Paper](https://arxiv.org/abs/1812.03282)]**
- [A tiny, friendly, strong pytorch implement of person re-identification baseline. **Tutorial**](https://github.com/layumi/Person_reID_baseline_pytorch),CVPR 2019,  **[[Paper](https://arxiv.org/abs/1904.07223)]**

- [Progressive Pose Attention for Person Image Generation](https://github.com/tengteng95/Pose-Transfer),CVPR 2019,**[[Paper](http://arxiv.org/abs/1904.03349)]**

- [FSA-Net: Learning Fine-Grained Structure Aggregation for Head Pose Estimation from a Single Image](https://github.com/shamangary/FSA-Net), CVPR 2019,**[[Paper](https://github.com/shamangary/FSA-Net/blob/master/0191.pdf)]**
- [An unoffical implemention for paper "Fast Human Pose Estimation"](https://github.com/yuanyuanli85/Fast_Human_Pose_Estimation_Pytorch), CVPR 2019,**[[Paper](https://arxiv.org/abs/1811.05419)]**
- [Real-time single person pose estimation for Android and iOS](https://github.com/edvardHua/PoseEstimationForMobile),æ‰‹æœºç«¯å®ç°äººä½“ä½å§¿ä¼°è®¡
- [Basics of 2D and 3D Human Pose Estimation](https://github.com/cbsudux/Human-Pose-Estimation-101),äººä½“å§¿æ€ä¼°è®¡å…¥é—¨
- [Libra R-CNN: Towards Balanced Learning for Object Detection](https://github.com/OceanPang/Libra_R-CNN)
- [High-resolution networks (HRNets) for object detection](https://github.com/HRNet/HRNet-Object-Detection), **[[Paper](https://arxiv.org/pdf/1904.04514.pdf)]**
- [Learning Correspondence from the Cycle-Consistency of Time](https://github.com/xiaolonw/TimeCycle), CVPR 2019, **[[Paper](https://arxiv.org/abs/1903.07593)]**
- [PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation](https://github.com/zju3dv/pvnet), CVPR 2019, **[[Paper](https://arxiv.org/abs/1812.11788)], [[Project Page](https://zju3dv.github.io/pvnet)]**
- [Self-Supervised Learning of 3D Human Pose using Multi-view Geometry](https://github.com/mkocabas/EpipolarPose), CVPR 2018, **[[Paper](https://arxiv.org/abs/1903.02330)]**
- [PifPaf: Composite Fields for Human Pose Estimation](https://github.com/vita-epfl/openpifpaf), **[[Paper](https://arxiv.org/abs/1903.06593)]** 
- [Deep High-Resolution Representation Learning for Human Pose Estimation](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch),CVPR 2019, **[[Paper](https://arxiv.org/pdf/1902.09212.pdf)]**, **[[Project Page](https://jingdongwang2017.github.io/Projects/HRNet/PoseEstimation.html)]**
- [PoseFlow: Efficient Online Pose Tracking)](https://github.com/YuliangXiu/PoseFlow), BMVC 2018, **[[Paper](https://arxiv.org/abs/1802.00977)]**
- [A Bottom-Up Clustering Approach to Unsupervised Person Re-identification](https://github.com/vana77/Bottom-up-Clustering-Person-Re-identification)ï¼ŒAAAI 2019, é‡å®šä½
- [Fast Online Object Tracking and Segmentation: A Unifying Approach](https://github.com/foolwood/SiamMask),CVPR 2019,**[[Paper](https://arxiv.org/abs/1812.05050)] [[Video](https://youtu.be/I_iOVrcpEBw)] [[Project Page](http://www.robots.ox.ac.uk/~qwang/SiamMask)]**
- [SimpleDet - A Simple and Versatile Framework for Object Detection and Instance Recognition](https://github.com/TuSimple/simpledet),**[[Paper](https://arxiv.org/abs/1903.05831)]** 

## Depth/Disparity & Flow estimation 

- [**Depth**][SemiGlobalMatching](https://github.com/ethan-li-coding/SemiGlobalMatching), SGMåŒç›®ç«‹ä½“åŒ¹é…ç®—æ³•å®Œæ•´å®ç°ï¼Œä»£ç è§„èŒƒï¼Œæ³¨é‡Šä¸°å¯Œä¸”æ¸…æ™°ï¼ŒCSDNåŒæ­¥æ•™å­¦

- [PointMVSNet: Point-based Multi-view Stereo Network](https://github.com/callmeray/PointMVSNet),ICCV 2019,**[[Paper](https://arxiv.org/abs/1908.04422)]**
- [DeepLiDAR](https://github.com/JiaxiongQ/DeepLiDAR),CVPR 2019, **[[Paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Qiu_DeepLiDAR_Deep_Surface_Normal_Guided_Depth_Prediction_for_Outdoor_Scene_CVPR_2019_paper.pdf)]**, å•å¼ RGBå›¾åƒ+ç¨€ç–é›·è¾¾æ•°æ®è¿›è¡Œå®¤å¤–åœºæ™¯æ·±åº¦ä¼°è®¡
- [Real-Time Monocular Depth Estimation using Synthetic Data with Domain Adaptation via Image Style Transfer](https://github.com/atapour/monocularDepth-Inference),CVPR 2018, **[[Paper](http://breckon.eu/toby/publications/papers/abarghouei18monocular.pdf)]**
- [Learning Single-Image Depth from Videos using Quality Assessment Networks](https://github.com/princeton-vl/YouTube3D),CVPR 2019, **[[Paper](https://arxiv.org/abs/1806.09573)]**, **[[Project Page](http://www-personal.umich.edu/~wfchen/youtube3d/)]**

- [SCDA: Adapting Object Detectors via Selective Cross-Domain Alignment](https://github.com/WERush/SCDA),CVPR 2019, **[[Paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Adapting_Object_Detectors_via_Selective_Cross-Domain_Alignment_CVPR_2019_paper.pdf)]**, **[[Project Page](http://zhuxinge.me/aboutme.html)]**

- [Learning monocular depth estimation infusing traditional stereo knowledge](https://github.com/fabiotosi92/monoResMatch-Tensorflow),CVPR 2019,**[[PDF](https://vision.disi.unibo.it/~ftosi/papers/monoResMatch.pdf)]**
- [HPLFlowNet: Hierarchical Permutohedral Lattice FlowNet for Scene Flow Estimation on Large-scale Point Clouds](https://github.com/laoreja/HPLFlowNet),CVPR 2019,**[[Paper](hhttps://web.cs.ucdavis.edu/~yjlee/projects/cvpr2019-HPLFlowNet.pdf)]**
- [GA-Net: Guided Aggregation Net for End-to-end Stereo Matching](https://github.com/feihuzhang/GANet),CVPR 2019,**[[Paper](https://arxiv.org/pdf/1904.06587.pdf)]**
- [DPSNet: End-to-end Deep Plane Sweep Stereo](https://github.com/sunghoonim/DPSNet),ICLR 2019,**[[Paper](https://openreview.net/pdf?id=ryeYHi0ctQ)]**
- [Fast Depth Densification for Occlusion-aware Augmented Reality](https://github.com/muskie82/AR-Depth-cpp), SIGGRAPH-Asia 2018, **[[Project Page](https://homes.cs.washington.edu/~holynski/publications/occlusion/index.html)]**,[another version](https://github.com/facebookresearch/AR-Depth)
- [Learning To Adapt For Stereo](https://github.com/CVLAB-Unibo/Learning2AdaptForStereo), CVPR 2019, **[[Paper](https://arxiv.org/pdf/1904.02957)]**
- [Pyramid Stereo Matching Network](https://github.com/JiaRenChang/PSMNet),**[[Paper](https://arxiv.org/abs/1803.08669)]** 
- [Bridging Stereo Matching and Optical Flow via Spatiotemporal Correspondence](https://github.com/lelimite4444/BridgeDepthFlow), **[[Paper](https://arxiv.org/abs/1905.09265)]**
- [Sparse Depth Completion](https://github.com/wvangansbeke/Sparse-Depth-Completion), **[[Paper](https://arxiv.org/pdf/1902.05356.pdf)]**, RGBå›¾åƒè¾…åŠ©é›·è¾¾æ·±åº¦ä¼°è®¡
- [GASDA](https://github.com/sshan-zhao/GASDA), CVPR 2019, **[[Paper](https://sshan-zhao.github.io/papers/gasda.pdf)]**
- [MVSNet: Depth Inference for Unstructured Multi-view Stereo](https://github.com/xy-guo/MVSNet_pytorch), **[[Paper](https://arxiv.org/abs/1804.02505)]**, éå®˜æ–¹å®ç°ç‰ˆæœ¬çš„MVSNet
- [Stereo R-CNN based 3D Object Detection for Autonomous Driving](https://github.com/HKUST-Aerial-Robotics/Stereo-RCNN), CVPR 2019, **[[Paper](https://arxiv.org/pdf/1902.09738.pdf)]**
- [Real-time self-adaptive deep stereo](https://github.com/CVLAB-Unibo/Real-time-self-adaptive-deep-stereo), CVPR 2019, **[[Paper](https://arxiv.org/abs/1810.05424)]**
- [High Quality Monocular Depth Estimation via Transfer Learning](https://github.com/ialhashim/DenseDepth),CVPR 2019, **[[Paper](https://arxiv.org/abs/1812.11941)]**, **[[Project Page](https://ialhashim.github.io/publications/index.html)]**
- [Group-wise Correlation Stereo Network](https://github.com/xy-guo/GwcNet),CVPR 2019, **[[Paper](https://arxiv.org/abs/1903.04025)]**
- [DeepMVS: Learning Multi-View Stereopsis](https://github.com/phuang17/DeepMVS), CVPR 2018,**[[Project Page](https://phuang17.github.io/DeepMVS/index.html)]**,å¤šç›®æ·±åº¦ä¼°è®¡
- [FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks](https://github.com/sampepose/flownet2-tf), CVPR 2017, æ·±åº¦å­¦ä¹ å…‰æµæ¢å¤
- [StereoVision-ADCensus](https://github.com/DLuensch/StereoVision-ADCensus),æ·±åº¦æ¢å¤ä»£ç é›†åˆ(**ADCensus, SGBM, BM**)
- [SegStereo: Exploiting Semantic Information for Disparity Estimation](https://github.com/yangguorun/SegStereo), æ¢ç©¶è¯­ä¹‰ä¿¡æ¯åœ¨æ·±åº¦ä¼°è®¡ä¸­çš„ä½œç”¨
- [Light Filed Depth Estimation using GAN](https://github.com/kuantingchen04/Light-Field-Depth-Estimation)ï¼Œåˆ©ç”¨GANè¿›è¡Œå…‰åœºæ·±åº¦æ¢å¤
- [EV-FlowNet: Self-Supervised Optical Flow for Event-based Cameras](https://github.com/daniilidis-group/EV-FlowNet),Proceedings of Robotics 2018,**[[Paper](https://arxiv.org/abs/1802.06898)]**
- [DF-Net: Unsupervised Joint Learning of Depth and Flow using Cross-Task Consistency](https://github.com/vt-vl-lab/DF-Net), ECCV 2018, **[[Paper](https://arxiv.org/abs/1809.01649)]**
- [GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose](https://github.com/yzcjtr/GeoNet), CVPR 2018, **[[Paper](https://arxiv.org/abs/1803.02276)]**

## 3D & Graphic
- [PRNet: Self-Supervised Learning for Partial-to-Partial Registration](https://github.com/WangYueFt/prnet),NeurIPS 2019
- [Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop](https://github.com/nkolot/SPIN),ICCV 2019, **[[Paper](https://arxiv.org/pdf/1909.12828.pdf)]** , **[[Project Page](https://www.seas.upenn.edu/~nkolot/projects/spin/)]** 
- [Cross View Fusion for 3D Human Pose Estimation](https://github.com/microsoft/multiview-human-pose-estimation-pytorch),ICCV 2019, **[[Paper](https://arxiv.org/abs/1909.01203)]** ,è·¨è§†è§’3Dä½å§¿ä¼°è®¡
- [MVF-Net: Multi-View 3D Face Morphable Model Regression](https://github.com/Fanziapril/mvfnet),å¤šè§†è§’3Däººè„¸é‡å»º, **[[Paper](https://arxiv.org/abs/1904.04473)]** 
- [KillingFusion](https://github.com/saurabheights/KillingFusion)

- [ReFusion: 3D Reconstruction in Dynamic Environments for RGB-D Cameras Exploiting Residuals](https://github.com/PRBonn/refusion), **[[Paper](https://arxiv.org/pdf/1905.02082.pdf)]** 

- [densebody_pytorch](https://github.com/Lotayou/densebody_pytorch), **[[Paper](https://arxiv.org/abs/1903.10153v3)]** 
- [Single-Image Piece-wise Planar 3D Reconstruction via Associative Embedding](https://github.com/svip-lab/PlanarReconstruction),CVPR 2019, **[[Paper](https://arxiv.org/pdf/1902.09777.pdf)]**, å•ç›®3Dé‡å»º
- [HorizonNet: Learning Room Layout with 1D Representation and Pano Stretch Data Augmentation](https://github.com/sunset1995/HorizonNet),CVPR 2019, **[[Paper](https://arxiv.org/abs/1901.03861)]**, æ·±åº¦å­¦ä¹ å…¨æ™¯è½¬3D
- [Adaptive O-CNN: A Patch-based Deep Representation of 3D Shapes](https://github.com/Microsoft/O-CNN),SIGGRAPH Asia 2018, **[[Project Page](https://wang-ps.github.io/AO-CNN.html)]**


## Other Collections

- [chinese-independent-blogs](https://github.com/timqian/chinese-independent-blogs), ä¸­æ–‡ç‹¬ç«‹åšå®¢é›†é”¦

- [StructureFlow: Image Inpainting via Structure-aware Appearance Flow](https://github.com/RenYurui/StructureFlow),å›¾åƒinpainting

- [free-books](https://github.com/ruanyf/free-books),äº’è”ç½‘ä¸Šçš„å…è´¹ä¹¦ç±

- [AcademicPages](https://github.com/academicpages/academicpages.github.io),é€šç”¨çš„å­¦æœ¯ä¸»é¡µæ¨¡ç‰ˆ

- [MMdnn](https://github.com/microsoft/MMdnn),å®ç°æ·±åº¦å­¦ä¹ æ¨¡å‹ä¹‹é—´çš„ç›¸äº’è½¬æ¢
- [tensorflow2caffemodel](https://github.com/abner2015/tensorflow2caffemodel),tensorflowæ¨¡å‹è½¬caffemodel
- [lihang-code](https://github.com/fengdu78/lihang-code),ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹çš„ä»£ç å®ç°
- [sse2neon](https://github.com/DLTcollab/sse2neon),[sse2neon](https://github.com/jratcliff63367/sse2neon),SSEè½¬neonï¼ŒåµŒå…¥å¼ç§»æ¤æ—¶å¯èƒ½ä¼šç”¨åˆ°;
- [Production-Level-Deep-Learning](https://github.com/alirezadir/Production-Level-Deep-Learning),æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ¨ç½²æµç¨‹
- [åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ Dive-into-DL-PyTorch](https://github.com/ShusenTang/Dive-into-DL-PyTorch)
- [machine-learning-yearning-cn](https://github.com/deeplearning-ai/machine-learning-yearning-cn)ï¼ŒMachine Learning Yearning ä¸­æ–‡ç‰ˆ - ã€Šæœºå™¨å­¦ä¹ è®­ç»ƒç§˜ç±ã€‹ - Andrew Ng è‘—
- [academicpages.github.io](https://github.com/academicpages/academicpages.github.io)ï¼Œå­¦æœ¯ä¸»é¡µæ¨¡æ¿
- [Coursera-ML-AndrewNg-Notes](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes),å´æ©è¾¾è€å¸ˆçš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ä¸ªäººç¬”è®°
- [machine-learning-notes](https://github.com/roboticcam/machine-learning-notes),æœºå™¨å­¦ä¹ ï¼Œæ¦‚ç‡æ¨¡å‹å’Œæ·±åº¦å­¦ä¹ çš„è®²ä¹‰(1500+é¡µ)å’Œè§†é¢‘é“¾æ¥
- [CNN-Visualization](https://github.com/scutan90/CNN-Visualization),CNNå¯è§†åŒ–ã€ç†è§£CNN
- [Awesome Semantic Segmentation](https://github.com/mrgloom/awesome-semantic-segmentation), è¯­ä¹‰åˆ†å‰²é›†åˆ
- [IROS2018 SLAM Collections](https://github.com/mengyuest/iros2018-slam-papers), IROS 2018é›†åˆ
- [VP-SLAM-SC-papers](https://github.com/TerenceCYJ/VP-SLAM-SC-papers),Visual Positioning & SLAM & Spatial Cognition è®ºæ–‡ç»Ÿè®¡ä¸åˆ†æ
- [Awesome System for Machine Learning](https://github.com/HuaizhengZhang/Awesome-System-for-Machine-Learning)
- [Machine-Learning-With-Python](https://github.com/Thinkgamer/Machine-Learning-With-Python), ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹pythonä»£ç å®ç°
- [How to learn robotics](https://github.com/qqfly/how-to-learn-robotics), å¼€æºæœºå™¨äººå­¦å­¦ä¹ æŒ‡å—
- [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision),DLåœ¨CVé¢†åŸŸçš„åº”ç”¨
- [Single-Image-Super-Resolution](https://github.com/YapengTian/Single-Image-Super-Resolution), ä¸€ä¸ªæœ‰å…³**å›¾åƒè¶…åˆ†è¾¨**çš„åˆé›†
- [ai report](https://github.com/wifity/ai-report), AIç›¸å…³çš„ç ”ç©¶æŠ¥å‘Š
- [State-of-the-art papers and code](https://paperswithcode.com/sota),æœé›†äº†ç›®å‰sotaçš„è®ºæ–‡ä»¥åŠä»£ç 
- [CVPR 2019 (Papers/Codes/Project/Paper reading)](https://github.com/extreme-assistant/cvpr2019)
- [A curated list of papers & resources linked to 3D reconstruction from images](https://github.com/openMVG/awesome_3DReconstruction_list),æœ‰å…³ä¸‰ç»´é‡å»ºçš„è®ºæ–‡æ±‡æ€»
- [SLAM-Jobs](https://github.com/nebula-beta/SLAM-Jobs), SLAM/SFMæ±‚èŒæŒ‡å—

- [Spatial Attentive Single-Image Deraining with a High Quality Real Rain Dataset](https://github.com/stevewongv/SPANet),CVPR 2019,å»é›¨
- [Densely Connected Pyramid Dehazing Network](https://github.com/hezhangsprinter/DCPDN),CVPR 2018,å»é›¾
- [MMSR](https://github.com/open-mmlab/mmsr)ï¼ŒMMLABæ¨å‡ºçš„è¶…åˆ†è¾¨å·¥å…·ç®±
- [æ·±åº¦å­¦ä¹ OCR](https://github.com/Bartzi/stn-ocr)
- [è¥¿ç“œä¹¦ğŸ‰å­¦ä¹ ç¬”è®°](https://github.com/Vay-keen/Machine-learning-learning-notes)
- [awesome-reinforcement-learning-zh](https://github.com/wwxFromTju/awesome-reinforcement-learning-zh),å¼ºåŒ–å­¦ä¹ ä»å…¥é—¨åˆ°æ”¾å¼ƒçš„èµ„æ–™

- [Deep Plug-and-Play Super-Resolution for Arbitrary Blur Kernels](https://github.com/cszn/DPSR),CVPR 2019,è¶…åˆ†è¾¨
- [Cool Fashion Papers](https://github.com/lzhbrian/Cool-Fashion-Papers), Cool resources about Fashion + AI.
- [Deep Flow-Guided Video Inpainting](https://github.com/nbei/Deep-Flow-Guided-Video-Inpainting),CVPR 2019, **[[Paper](https://arxiv.org/pdf/1806.10447.pdf)]** ,å›¾åƒä¿®å¤
- [YOLACT: Real-time Instance Segmentation](https://github.com/dbolya/yolact)
- [LPRNet: License Plate Recognition via Deep Neural Networks](https://github.com/lyl8213/Plate_Recognition-LPRnet), **[[Paper](https://arxiv.org/pdf/1806.10447.pdf)]** 
- [CHINESE-OCR](https://github.com/xiaofengShi/CHINESE-OCR), è¿ç”¨tfå®ç°è‡ªç„¶åœºæ™¯æ–‡å­—æ£€æµ‹
- [BeautyCamera](https://github.com/PerpetualSmile/BeautyCamera), ç¾é¢œç›¸æœºï¼Œå…·æœ‰äººè„¸æ£€æµ‹ã€ç£¨çš®ç¾ç™½äººè„¸ã€æ»¤é•œã€è°ƒèŠ‚å›¾ç‰‡ã€æ‘„åƒåŠŸèƒ½
- [CV-arXiv-Daily](https://github.com/zhengzhugithub/CV-arXiv-Daily), åˆ†äº«è®¡ç®—æœºè§†è§‰æ¯å¤©çš„arXivæ–‡ç« 
- [Pluralistic-Inpainting](https://github.com/lyndonzheng/Pluralistic-Inpainting), [ArXiv](https://arxiv.org/abs/1903.04227) | [Project Page](http://www.chuanxiaz.com/publication/pluralistic/) | [Online Demo](http://www.chuanxiaz.com/project/pluralistic/) | [Video(demo)](https://www.youtube.com/watch?v=9V7rNoLVmSs)
- [An Interactive Introduction to Fourier Transforms](https://github.com/Jezzamonn/fourier), è¶…æ£’çš„å‚…é‡Œå¶å˜æ¢å›¾å½¢åŒ–è§£é‡Š
- [pumpkin-book](https://github.com/datawhalechina/pumpkin-book), ã€Šæœºå™¨å­¦ä¹ ã€‹ï¼ˆè¥¿ç“œä¹¦ï¼‰å…¬å¼æ¨å¯¼è§£æ
- [Julia](https://github.com/JuliaLang/julia)
- [A Julia machine learning framework](https://github.com/alan-turing-institute/MLJ.jl)ï¼Œä¸€ç§åŸºäºJuliaçš„æœºå™¨å­¦ä¹ æ¡†æ¶
- [High-Performance Face Recognition Library on PyTorch](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch)ï¼Œäººè„¸è¯†åˆ«åº“
- [Deep-Learning-Coursera](https://github.com/enggen/Deep-Learning-Coursera)ï¼Œæ·±åº¦å­¦ä¹ æ•™ç¨‹ï¼ˆdeeplearning.aiï¼‰
- [The best resources around Machine Learning](https://github.com/RemoteML/bestofml)
- [VGGFace2: A dataset for recognising faces across pose and age](https://github.com/cydonia999/VGGFace2-pytorch)
- [Statistical learning methods](https://github.com/SmirkCao/Lihang)ï¼Œç»Ÿè®¡å­¦ä¹ æ–¹æ³•
- [End-to-end Adversarial Learning for Generative Conversational Agents](https://live.bilibili.com/7332534?visit_id=9ytrx9lpsy80)ï¼Œ2017ï¼Œä»‹ç»äº†ä¸€ç§ç«¯åˆ°ç«¯çš„åŸºäºGANçš„èŠå¤©æœºå™¨äºº
- [Residual Non-local Attention Networks for Image Restoration](https://github.com/yulunzhang/RNAN),ICLR 2019.
- [MSGAN: Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis](https://github.com/HelenMao/MSGAN), CVPR 2019,**[[Paper](https://arxiv.org/abs/1903.05628)]**
- [SPADE: Semantic Image Synthesis with Spatially-Adaptive Normalization](https://github.com/NVlabs/SPADE),CVPR 2019, **[[Project Page](https://nvlabs.github.io/SPADE/)]**
- [Faceswap with Pytorch or DeepFake with Pytorch](https://github.com/Oldpan/Faceswap-Deepfake-Pytorch), æ¢è„¸
- [DeepFaceLab](https://github.com/iperov/DeepFaceLab), æ¢è„¸

## Contribute

â¤ Please feel free to pull requests to add links.

## License

[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)
